{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe86ed7b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Lab Four: The Multi-Layer Perceptron\n",
    " \n",
    "\n",
    "#### Everett Cienkus, Blake Miller, Colin Weil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adba831",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. Load, Split, and Balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d55b544",
   "metadata": {},
   "source": [
    "#### 1.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d18a0766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the data into memory and save it to a pandas data frame.\n",
    "df = pd.read_csv('census_dataset/acs2017_census_tract_data.csv')\n",
    "\n",
    "# Remove any observations that having missing data.\n",
    "df = df.dropna()\n",
    "\n",
    "# Encode any string data as integers for now. \n",
    "le = LabelEncoder()\n",
    "s = le.fit_transform(df['State'])\n",
    "df['State'] = s\n",
    "c = le.fit_transform(df['County'])\n",
    "df['County'] = c\n",
    "\n",
    "X = df.drop(columns = ['ChildPoverty'])\n",
    "y = df['ChildPoverty']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde18112",
   "metadata": {},
   "source": [
    "Discuss why we are going to keep/ not keep county variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3875015a",
   "metadata": {},
   "source": [
    "#### 1.2 Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b74a3b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00e+00 3.91e+03]\n",
      " [1.00e-01 1.90e+01]\n",
      " [2.00e-01 2.20e+01]\n",
      " ...\n",
      " [9.78e+01 1.00e+00]\n",
      " [9.83e+01 1.00e+00]\n",
      " [1.00e+02 4.40e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Divide your data into training and testing data using an 80% training \n",
    "# and 20% testing split. Use the cross validation modules that are part \n",
    "# of scikit-learn.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, train_size=0.8)\n",
    "\n",
    "unique_ytrain, counts_ytrain = np.unique(y_train, return_counts=True)\n",
    "print(np.asarray((unique_ytrain, counts_ytrain)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3442dce",
   "metadata": {},
   "source": [
    "#### 1.3 Balance (NOT DONE) Should we use state maybe? or just do the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dad64985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14543.5\n",
      "14424\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m X_train\u001b[38;5;241m.\u001b[39mhead()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_train[X_train\u001b[38;5;241m.\u001b[39mState \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m10\u001b[39m]))\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_train[X_train\u001b[38;5;241m.\u001b[39mState \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m9\u001b[39m \u001b[38;5;241m&\u001b[39m X_train\u001b[38;5;241m.\u001b[39mState \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m20\u001b[39m]))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:1527\u001b[0m, in \u001b[0;36mNDFrame.__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__nonzero__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1528\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe truth value of a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is ambiguous. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1529\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1530\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "print(len(X_train)/4)\n",
    "\n",
    "X_train.head()\n",
    "\n",
    "print(len(X_train[X_train.State < 10]))\n",
    "# print(len(X_train[X_train.State > 9 & X_train.State < 20]))\n",
    "\n",
    "# all factors are {1, 2, 103, 206, 353, 706, 36359, 72718}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6a5cf2",
   "metadata": {},
   "source": [
    "We balance the training and not the testing set because it is good to balance for training because then we have information for all of our classes but when we are testing, we want to test on the distributuion that would actually be the case in order to get an accurate represenation of the results for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c821cc7",
   "metadata": {},
   "source": [
    "### 2. Pre-proccesing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957f1fd4",
   "metadata": {},
   "source": [
    "MEGNEMAR for comparing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fa3adf",
   "metadata": {},
   "source": [
    "### 3. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bf5e64",
   "metadata": {},
   "source": [
    "Feed forward/ back propogation in for-loop for adding layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e55130d",
   "metadata": {},
   "source": [
    "### 4. Adaptive momentum (AdaM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbcdf01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
