{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe86ed7b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Lab Three: Extending Logistic Regression\n",
    " \n",
    "\n",
    "#### Everett Cienkus, Blake Miller, Colin Weil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adba831",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. Preparation and Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2d0a31",
   "metadata": {},
   "source": [
    "#### 1.1 Business Case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ec3bca",
   "metadata": {},
   "source": [
    "Explain the task and what business-case or use-case it is designed to solve (or designed to investigate). Detail exactly what the classification task is and what parties would be interested in the results. For example, would the model be deployed or used mostly for offline analysis? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43ab6fd",
   "metadata": {},
   "source": [
    "#### 1.2 Preparation of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8d95709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and prepare your class variables. \n",
    "# Use proper variable representations (int, float, one-hot, etc.). \n",
    "# Use pre-processing methods (as needed) for dimensionality reduction, \n",
    "# scaling, etc. Remove variables that are not needed/useful for the analysis. \n",
    "# Describe the final dataset that is used for classification/regression \n",
    "# (include a description of any newly formed variables you created).\n",
    "# MAKE SURE TO NORMALIZE VALUES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ff4056",
   "metadata": {},
   "source": [
    "#### 1.3 Division of Trainig and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7b70605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide your data into training and testing data using an 80% training \n",
    "# and 20% testing split. Use the cross validation modules that are part \n",
    "# of scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a49299",
   "metadata": {},
   "source": [
    "Argue \"for\" or \"against\" splitting your data using an 80/20 split. That is, why is the 80/20 split appropriate (or not) for your dataset?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19215c4d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "### 2. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15406538",
   "metadata": {},
   "source": [
    "### 3. Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154f4961",
   "metadata": {},
   "source": [
    "### 4. BFGS (Can change but thought this would be better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d22bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of BFGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccbf31d",
   "metadata": {},
   "source": [
    "Compare your performance accuracy and runtime to the BFGS implementation in SciPy (that we used in lecture). \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
