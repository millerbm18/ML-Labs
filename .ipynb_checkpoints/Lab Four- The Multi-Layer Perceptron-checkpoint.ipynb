{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe86ed7b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Lab Four: The Multi-Layer Perceptron\n",
    " \n",
    "\n",
    "#### Everett Cienkus, Blake Miller, Colin Weil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adba831",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. Load, Split, and Balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d55b544",
   "metadata": {},
   "source": [
    "#### 1.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d18a0766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the data into memory and save it to a pandas data frame.\n",
    "df = pd.read_csv('census_dataset/acs2017_census_tract_data.csv')\n",
    "\n",
    "# Remove any observations that having missing data.\n",
    "df = df.dropna()\n",
    "\n",
    "# Encode any string data as integers for now. \n",
    "le = LabelEncoder()\n",
    "s = le.fit_transform(df['State'])\n",
    "df['State'] = s\n",
    "c = le.fit_transform(df['County'])\n",
    "df['County'] = c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c7bb65",
   "metadata": {},
   "source": [
    "We are going to keep the county variable because this has many effects on if a child is in poverty or not. For example, somewhere like in Illinois, there can be a county that is one of the most rich counties in the country, a county that contains the inner city of Chicago, and a town in the Southwest of the state that is mostly farms. These three places are all very different and the county is a very good way to differentiate them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3875015a",
   "metadata": {},
   "source": [
    "#### 1.2 Split Dataset and Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad64985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.2 16.3 31.6\n",
      "[[    1 14596]\n",
      " [    2 14567]\n",
      " [    3 14545]\n",
      " [    4 14466]]\n",
      "58174\n"
     ]
    }
   ],
   "source": [
    "# Divide your data into training and testing data using an 80% training \n",
    "# and 20% testing split. Use the cross validation modules that are part \n",
    "# of scikit-learn.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def SplitAndBalance(df, out=False):\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, train_size=0.8)\n",
    "\n",
    "    # Uses quantization thresholds for the \"ChildPoverty\" \n",
    "    # variable that equally divide the data into four classes\n",
    "    q1, q2, q3 = df['ChildPoverty'].quantile([0.25,0.5,0.75])\n",
    "    if out: print(q1,q2,q3)\n",
    "    df_train['quantized_childPoverty'] = pd.cut(x=df_train['ChildPoverty'], bins=[-1,q1,q2,q3,101], labels=[1,2,3,4])\n",
    "    X_train = df_train.drop(columns = ['ChildPoverty','quantized_childPoverty']).to_numpy()\n",
    "    y_train = df_train['quantized_childPoverty'].to_numpy()\n",
    "\n",
    "    df_test['quantized_childPoverty'] = pd.cut(x=df_test['ChildPoverty'], bins=[-1,q1,q2,q3,101], labels=[1,2,3,4])\n",
    "    X_test = df_test.drop(columns = ['ChildPoverty','quantized_childPoverty']).to_numpy()\n",
    "    y_test = df_test['quantized_childPoverty'].to_numpy()\n",
    "\n",
    "    if out:\n",
    "        unique_ytrain, counts_ytrain = np.unique(y_train, return_counts=True)\n",
    "        print(np.asarray((unique_ytrain, counts_ytrain)).T)\n",
    "        print(len(y_train))\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = SplitAndBalance(df, out=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6a5cf2",
   "metadata": {},
   "source": [
    "We balance the training and not the testing set because it is good to balance for training because then we have information for all of our classes but when we are testing, we want to test on the distributuion that would actually be the case in order to get an accurate represenation of the results for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c821cc7",
   "metadata": {},
   "source": [
    "### 2. Pre-proccesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3a8165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def print_result(nn,X_train,y_train,X_test,y_test,title=\"\",color=\"red\"):\n",
    "    \n",
    "    print(\"=================\")\n",
    "    print(title,\":\")\n",
    "    yhat = nn.predict(X_train)\n",
    "    print('Resubstitution acc:',accuracy_score(y_train,yhat))\n",
    "    \n",
    "    yhat = nn.predict(X_test)\n",
    "    print('Validation acc:',accuracy_score(y_test,yhat))\n",
    "    \n",
    "    if hasattr(nn,'val_score_'):\n",
    "        plt.plot(range(len(nn.val_score_)), nn.val_score_, color=color,label=title)\n",
    "        plt.ylabel('Validation Accuracy')\n",
    "    else:\n",
    "        plt.plot(range(len(nn.score_)), nn.score_, color=color,label=title)\n",
    "        plt.ylabel('Resub Accuracy')\n",
    "        \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.tight_layout()\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d00de5",
   "metadata": {},
   "source": [
    "#### 2.1 Two-Layer Perceptron Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07ad7084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example adapted from https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch12/ch12.ipynb\n",
    "# Original Author: Sebastian Raschka\n",
    "\n",
    "# This is the optional book we use in the course, excellent intuitions and straightforward programming examples\n",
    "# please note, however, that this code has been manipulated to reflect our assumptions and notation.\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# start with a simple base classifier, which can't be fit or predicted\n",
    "# it only has internal classes to be used by classes that will subclass it\n",
    "class TwoLayerPerceptronBase(object):\n",
    "    def __init__(self, n_hidden=30,\n",
    "                 C=0.0, epochs=500, eta=0.001, random_state=None):\n",
    "        np.random.seed(random_state)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.l2_C = C\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        \n",
    "    @staticmethod\n",
    "    def _encode_labels(y):\n",
    "        \"\"\"Encode labels into one-hot representation\"\"\"\n",
    "        onehot = pd.get_dummies(y).values.T\n",
    "            \n",
    "        return onehot\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights with small random numbers.\"\"\"\n",
    "        W1_num_elems = (self.n_features_)*self.n_hidden\n",
    "        W1 = np.random.uniform(-1.0, 1.0, size=W1_num_elems)\n",
    "        W1 = W1.reshape(self.n_hidden, self.n_features_) # reshape to be W\n",
    "        b1 = np.zeros((self.n_hidden, 1))\n",
    "        \n",
    "        W2_num_elems = (self.n_hidden)*self.n_output_\n",
    "        W2 = np.random.uniform(-1.0, 1.0, size=W2_num_elems)\n",
    "        W2 = W2.reshape(self.n_output_, self.n_hidden)\n",
    "        b2 = np.zeros((self.n_output_, 1))\n",
    "        \n",
    "        return W1, W2, b1, b2\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(z):\n",
    "        \"\"\"Use scipy.special.expit to avoid overflow\"\"\"\n",
    "        # 1.0 / (1.0 + np.exp(-z))\n",
    "        return expit(z)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def _L2_reg(lambda_, W1, W2):\n",
    "        \"\"\"Compute L2-regularization cost\"\"\"\n",
    "        # only compute for non-bias terms\n",
    "        return (lambda_/2.0) * np.sqrt(np.mean(W1[:, 1:] ** 2) + np.mean(W2[:, 1:] ** 2))\n",
    "    \n",
    "    def _cost(self,A3,Y_enc,W1,W2):\n",
    "        '''Get the objective function value'''\n",
    "        cost = np.mean((Y_enc-A3)**2)\n",
    "        L2_term = self._L2_reg(self.l2_C, W1, W2)\n",
    "        return cost + L2_term\n",
    "    \n",
    "    def _feedforward(self, X, W1, W2, b1, b2):\n",
    "        \"\"\"Compute feedforward step\n",
    "        -----------\n",
    "        X : Input layer with original features.\n",
    "        W1: Weight matrix for input layer -> hidden layer.\n",
    "        W2: Weight matrix for hidden layer -> output layer.\n",
    "        ----------\n",
    "        a1-a3 : activations into layer (or output layer)\n",
    "        z1-z2 : layer inputs \n",
    "\n",
    "        \"\"\"\n",
    "        A1 = X.T\n",
    "        Z1 = W1 @ A1 + b1\n",
    "        A2 = self._sigmoid(Z1)\n",
    "        Z2 = W2 @ A2 + b2\n",
    "        A3 = self._sigmoid(Z2)\n",
    "        return A1, Z1, A2, Z2, A3\n",
    "    \n",
    "    def _get_gradient(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        # vectorized backpropagation\n",
    "        V2 = -2*(Y_enc-A3)*A3*(1-A3)\n",
    "        V1 = A2*(1-A2)*(W2.T @ V2)\n",
    "        \n",
    "        gradW2 = V2 @ A2.T\n",
    "        gradW1 = V1 @ A1.T\n",
    "        \n",
    "        gradb2 = np.sum(V2, axis=1).reshape((-1,1))\n",
    "        gradb1 = np.sum(V1, axis=1).reshape((-1,1))\n",
    "        \n",
    "        \n",
    "        # regularize weights that are not bias terms\n",
    "        gradW1 += W1 * self.l2_C\n",
    "        gradW2 += W2 * self.l2_C\n",
    "\n",
    "        return gradW1, gradW2, gradb1, gradb2\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels\"\"\"\n",
    "        _, _, _, _, A3 = self._feedforward(X, self.W1, self.W2, self.b1, self.b2)\n",
    "        y_pred = np.argmax(A3, axis=0)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df1e0f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# just start with the vectorized version and minibatch\n",
    "class TLPMiniBatch(TwoLayerPerceptronBase):\n",
    "    def __init__(self, alpha=0.0, decrease_const=0.1, \n",
    "                 decrease_iter = 10, shuffle=True, \n",
    "                 minibatches=1, **kwds):        \n",
    "        # need to add to the original initializer \n",
    "        self.alpha = alpha\n",
    "        self.decrease_const = decrease_const\n",
    "        self.decrease_iter = decrease_iter\n",
    "        self.shuffle = shuffle\n",
    "        self.minibatches = minibatches\n",
    "        # but keep other keywords\n",
    "        super().__init__(**kwds)\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y, print_progress=False, XY_test=None):\n",
    "        \"\"\" Learn weights from training data. With mini-batch\"\"\"\n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "        Y_enc = self._encode_labels(y)\n",
    "        \n",
    "        # init weights and setup matrices\n",
    "        self.n_features_ = X_data.shape[1]\n",
    "        self.n_output_ = Y_enc.shape[0]\n",
    "        self.W1, self.W2, self.b1, self.b2 = self._initialize_weights()\n",
    "\n",
    "        # start momentum at zero for previous updates\n",
    "        rho_W1_prev = np.zeros(self.W1.shape) # for momentum\n",
    "        rho_W2_prev = np.zeros(self.W2.shape) # for momentum\n",
    "\n",
    "        self.cost_ = []\n",
    "        self.score_ = []\n",
    "        # get starting acc\n",
    "        self.score_.append(accuracy_score(y_data,self.predict(X_data)))\n",
    "        # keep track of validation, if given\n",
    "        if XY_test is not None:\n",
    "            X_test = XY_test[0].copy()\n",
    "            y_test = XY_test[1].copy()\n",
    "            self.val_score_ = []\n",
    "            self.val_score_.append(accuracy_score(y_test,self.predict(X_test)))\n",
    "            self.val_cost_ = []\n",
    "            \n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            # adaptive learning rate\n",
    "            # decrease at certain epochs\n",
    "            eta = self.eta * self.decrease_const**(np.floor(i/self.decrease_iter))\n",
    "\n",
    "            if print_progress>0 and (i+1)%print_progress==0:\n",
    "                sys.stderr.write('\\rEpoch: %d/%d' % (i+1, self.epochs))\n",
    "                sys.stderr.flush()\n",
    "\n",
    "            if self.shuffle:\n",
    "                idx_shuffle = np.random.permutation(y_data.shape[0])\n",
    "                X_data, Y_enc, y_data = X_data[idx_shuffle], Y_enc[:, idx_shuffle], y_data[idx_shuffle]\n",
    "\n",
    "            mini = np.array_split(range(y_data.shape[0]), self.minibatches)\n",
    "            mini_cost = []\n",
    "            for idx in mini:\n",
    "\n",
    "                # feedforward\n",
    "                A1, Z1, A2, Z2, A3 = self._feedforward(X_data[idx],\n",
    "                                                       self.W1,\n",
    "                                                       self.W2,\n",
    "                                                       self.b1,\n",
    "                                                       self.b2\n",
    "                                                      )\n",
    "                \n",
    "                cost = self._cost(A3,Y_enc[:, idx],self.W1,self.W2)\n",
    "                mini_cost.append(cost) # this appends cost of mini-batch only\n",
    "\n",
    "                # compute gradient via backpropagation\n",
    "                gradW1, gradW2, gradb1, gradb2 = self._get_gradient(A1=A1, A2=A2, A3=A3, Z1=Z1, Z2=Z2, \n",
    "                                                  Y_enc=Y_enc[:, idx],\n",
    "                                                  W1=self.W1,W2=self.W2)\n",
    "\n",
    "                # momentum calculations\n",
    "                rho_W1, rho_W2 = eta * gradW1, eta * gradW2\n",
    "                self.W1 -= (rho_W1 + (self.alpha * rho_W1_prev)) # update with momentum\n",
    "                self.W2 -= (rho_W2 + (self.alpha * rho_W2_prev)) # update with momentum\n",
    "                self.b1 -= eta * gradb1\n",
    "                self.b2 -= eta * gradb2\n",
    "                rho_W1_prev, rho_W2_prev = rho_W1, rho_W2\n",
    "                \n",
    "\n",
    "            self.cost_.append(np.mean(mini_cost))\n",
    "            self.score_.append(accuracy_score(y_data,self.predict(X_data)))\n",
    "            if XY_test is not None:\n",
    "                yhat = self.predict(X_test)\n",
    "                self.val_score_.append(accuracy_score(y_test,yhat))\n",
    "            \n",
    "        return self\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a72bb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to implement the new style of objective function, \n",
    "# we just need to update the final layer calculation of the gradient\n",
    "class TLPMiniBatchCrossEntropy(TLPMiniBatch):\n",
    "    def _cost(self,A3,Y_enc,W1,W2):\n",
    "        '''Get the objective function value'''\n",
    "        cost = -np.mean(np.nan_to_num((Y_enc*np.log(A3)+(1-Y_enc)*np.log(1-A3))))\n",
    "        L2_term = self._L2_reg(self.l2_C, W1, W2)\n",
    "        return cost + L2_term\n",
    "    \n",
    "    def _get_gradient(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        # vectorized backpropagation\n",
    "        V2 = (A3-Y_enc) # <- this is only line that changed\n",
    "        V1 = A2*(1-A2)*(W2.T @ V2)\n",
    "        \n",
    "        gradW2 = V2 @ A2.T\n",
    "        gradW1 = V1 @ A1.T\n",
    "        \n",
    "        gradb2 = np.sum(V2, axis=1).reshape((-1,1))\n",
    "        gradb1 = np.sum(V1, axis=1).reshape((-1,1))\n",
    "        \n",
    "        # regularize weights that are not bias terms\n",
    "        gradW1 += W1 * self.l2_C\n",
    "        gradW2 += W2 * self.l2_C\n",
    "\n",
    "        return gradW1, gradW2, gradb1, gradb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bab9cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLPBetterInitial(TLPMiniBatchCrossEntropy):             \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights Glorot and He normalization.\"\"\"\n",
    "        init_bound = 4*np.sqrt(6. / (self.n_hidden + self.n_features_))\n",
    "        W1 = np.random.uniform(-init_bound, init_bound,(self.n_hidden, self.n_features_))\n",
    "\n",
    "        # reduce the final layer magnitude in order to balance the size of the gradients\n",
    "        # between \n",
    "        init_bound = 4*np.sqrt(6 / (self.n_output_ + self.n_hidden))\n",
    "        W2 = np.random.uniform(-init_bound, init_bound,(self.n_output_, self.n_hidden)) \n",
    "        \n",
    "        b1 = np.zeros((self.n_hidden, 1))\n",
    "        b2 = np.zeros((self.n_output_, 1))\n",
    "        \n",
    "        return W1, W2, b1, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e01bd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 20/20"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.5 s, sys: 2.46 s, total: 12 s\n",
      "Wall time: 3.38 s\n",
      "=================\n",
      "Glorot Initial :\n",
      "Resubstitution acc: 0.25002578471482106\n",
      "Validation acc: 0.24773102310231024\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vals = { 'n_hidden':30, \n",
    "         'C':0.1, 'epochs':20, 'eta':0.001, # poor starting learning rate!!\n",
    "         'alpha':0.001, 'decrease_const':0.1, 'decrease_iter':15,\n",
    "         'minibatches':50,\n",
    "         'shuffle':True,'random_state':1}\n",
    "\n",
    "nn_better = TLPBetterInitial(**vals)\n",
    "%time nn_better.fit(X_train, y_train, print_progress=1, XY_test=(X_test, y_test))\n",
    "print_result(nn_better,X_train,y_train,X_test,y_test,title=\"Glorot Initial\",color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd8a6b7",
   "metadata": {},
   "source": [
    "#### 2.2 TLPNetwork with Normalizing the Continuous Numeric Feature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9830a5cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed eval>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mTLPMiniBatch.fit\u001b[0;34m(self, X, y, print_progress, XY_test)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_ \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# get starting acc\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_\u001b[38;5;241m.\u001b[39mappend(\u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_data\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# keep track of validation, if given\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m XY_test \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:85\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m---> 85\u001b[0m type_true \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred)\n\u001b[1;32m     88\u001b[0m y_type \u001b[38;5;241m=\u001b[39m {type_true, type_pred}\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/multiclass.py:324\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# check float and contains non-integer float values\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(y \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)):\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;66;03m# [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\u001b[39;00m\n\u001b[0;32m--> 324\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontinuous\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suffix\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:114\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    108\u001b[0m         allow_nan\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(X)\u001b[38;5;241m.\u001b[39many()\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(X)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m    112\u001b[0m     ):\n\u001b[1;32m    113\u001b[0m         type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfinity\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_nan \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN, infinity\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    115\u001b[0m             msg_err\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    116\u001b[0m                 type_err, msg_dtype \u001b[38;5;28;01mif\u001b[39;00m msg_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    117\u001b[0m             )\n\u001b[1;32m    118\u001b[0m         )\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "noncontinuous_df = df[['TractId','State','County','ChildPoverty']]\n",
    "X_normalized = pd.DataFrame(normalize(df.drop(columns = ['TractId','State','County','ChildPoverty'])))\n",
    "df_normalized = pd.concat([noncontinuous_df, X_normalized], axis=1)\n",
    "X_train, y_train, X_test, y_test = SplitAndBalance(df_normalized)\n",
    "\n",
    "%time nn_better.fit(X_train, y_train, print_progress=1, XY_test=(X_test, y_test))\n",
    "# print_result(nn_better,X_train,y_train,X_test,y_test,title=\"Glorot Initial\",color=\"blue\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6106ef76",
   "metadata": {},
   "source": [
    "#### 2.3 TLPNetwork with Normalizing + One Hot Encode the Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8add4163",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed eval>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mTLPMiniBatch.fit\u001b[0;34m(self, X, y, print_progress, XY_test)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_ \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# get starting acc\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_\u001b[38;5;241m.\u001b[39mappend(\u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_data\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# keep track of validation, if given\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m XY_test \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:85\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m---> 85\u001b[0m type_true \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred)\n\u001b[1;32m     88\u001b[0m y_type \u001b[38;5;241m=\u001b[39m {type_true, type_pred}\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/multiclass.py:324\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# check float and contains non-integer float values\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(y \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)):\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;66;03m# [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\u001b[39;00m\n\u001b[0;32m--> 324\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontinuous\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suffix\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:114\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    108\u001b[0m         allow_nan\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(X)\u001b[38;5;241m.\u001b[39many()\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(X)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m    112\u001b[0m     ):\n\u001b[1;32m    113\u001b[0m         type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfinity\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_nan \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN, infinity\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    115\u001b[0m             msg_err\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    116\u001b[0m                 type_err, msg_dtype \u001b[38;5;28;01mif\u001b[39;00m msg_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    117\u001b[0m             )\n\u001b[1;32m    118\u001b[0m         )\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================\n",
      "Glorot Initial :\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# One Hot Encode the Categorical Data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# perform one-hot encoding of the categorical data \"embarked\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# tmp_df = pd.get_dummies(df_imputed.Sex,prefix='Sex')\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# df_imputed = pd.concat((df_imputed,tmp_df),axis=1) # add back into the dataframe\u001b[39;00m\n\u001b[1;32m     11\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnn_better.fit(X_train, y_train, print_progress=1, XY_test=(X_test, y_test))\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mprint_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_better\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGlorot Initial\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mblue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mprint_result\u001b[0;34m(nn, X_train, y_train, X_test, y_test, title, color)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(title,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m yhat \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mpredict(X_train)\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResubstitution acc:\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43myhat\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     14\u001b[0m yhat \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation acc:\u001b[39m\u001b[38;5;124m'\u001b[39m,accuracy_score(y_test,yhat))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:85\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m---> 85\u001b[0m type_true \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred)\n\u001b[1;32m     88\u001b[0m y_type \u001b[38;5;241m=\u001b[39m {type_true, type_pred}\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/multiclass.py:324\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# check float and contains non-integer float values\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(y \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)):\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;66;03m# [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\u001b[39;00m\n\u001b[0;32m--> 324\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontinuous\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suffix\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:114\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    108\u001b[0m         allow_nan\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(X)\u001b[38;5;241m.\u001b[39many()\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(X)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m    112\u001b[0m     ):\n\u001b[1;32m    113\u001b[0m         type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfinity\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_nan \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN, infinity\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    115\u001b[0m             msg_err\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    116\u001b[0m                 type_err, msg_dtype \u001b[38;5;28;01mif\u001b[39;00m msg_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    117\u001b[0m             )\n\u001b[1;32m    118\u001b[0m         )\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# One Hot Encode the Categorical Data\n",
    "\n",
    "# perform one-hot encoding of the categorical data \"embarked\"\n",
    "# tmp_df = pd.get_dummies(df_imputed.Embarked,prefix='Embarked')\n",
    "# df_imputed = pd.concat((df_imputed,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "# tmp_df = pd.get_dummies(df_imputed.Sex,prefix='Sex')\n",
    "# df_imputed = pd.concat((df_imputed,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "\n",
    "%time nn_better.fit(X_train, y_train, print_progress=1, XY_test=(X_test, y_test))\n",
    "\n",
    "print_result(nn_better,X_train,y_train,X_test,y_test,title=\"Glorot Initial\",color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857a8e48",
   "metadata": {},
   "source": [
    "#### 2.4 Comparing the Performance of the Three Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1921e6e5",
   "metadata": {},
   "source": [
    "Are there any meaningful differences in performance? Explain, in your own words, why these models have (or do not have)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fa3adf",
   "metadata": {},
   "source": [
    "### 3. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bf5e64",
   "metadata": {},
   "source": [
    "Feed forward/ back propogation in for-loop for adding layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957f1fd4",
   "metadata": {},
   "source": [
    "MEGNEMAR for comparing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e55130d",
   "metadata": {},
   "source": [
    "### 4. Adaptive momentum (AdaM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbcdf01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
