{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe86ed7b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Lab Assignment Six: Convolutional Network Architectures\n",
    " \n",
    "\n",
    "#### Everett Cienkus, Blake Miller, Colin Weil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adba831",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fb0229",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1.1 Define and Prepare Class Variables\n",
    "Choose and explain what metric(s) you will use to evaluate your algorithmâ€™s performance. You should give a detailed argument for why this (these) metric(s) are appropriate on your data. That is, why is the metric appropriate for the task (e.g., in terms of the business case for the task). Please note: rarely is accuracy the best evaluation metric to use. Think deeply about an appropriate measure of performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bda77e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4eb04a66",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1.2. Choose Method for Dividing Data\n",
    "Choose the method you will use for dividing your data into training and testing (i.e., are you using Stratified 10-fold cross validation? Shuffle splits? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. Convince me that your cross validation method is a realistic mirroring of how an algorithm would be used in practice. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12aeb17",
   "metadata": {},
   "source": [
    "Since our dataset is over 50,000, it is okay to use 80/20 split according to the Larson Rule. This allows the data to be less biased, allowing the algorithm to train with a diverse dataset. The 80/20 rule works in this case bacause the large data set almost garentees that there will be diverse data because the set should contain multiple different combinations of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3f26fd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d748d3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af78583f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 2.1 Setup the Training to use Data Expansion in Keras\n",
    "Setup the training to use data expansion in Keras (also called data augmentation). Explain why the chosen data expansion techniques are appropriate for your dataset. You can use the keras ImageGenerator as a pre-processing step OR in the optimization loop. You can also use the Keras-cv augmenter (a separate package: https://keras.io/keras_cv/ Links to an external site.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "266716dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67692 training pictures loaded.\n",
      "22688 test images loaded.\n",
      "Num Classes: 131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(67692, 100, 100, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from numpy import asarray\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "    \n",
    "tf.random.set_seed(2)\n",
    "np.random.seed(0) # using this to help make results reproducible\n",
    "\n",
    "def get_data(dir):\n",
    "    images = []\n",
    "    targets = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "         for file in files:\n",
    "            with open(os.path.join(root, file), \"r\") as auto:\n",
    "                if file.lower().endswith('.jpg'):\n",
    "                    # Read in image as numpy arrays\n",
    "                    image = Image.open(os.path.join(root, file))\n",
    "                    # Recolor to black and white and flatten to 1D array\n",
    "                    np_img = np.array(image.convert('L')).flatten()\n",
    "                    # Add to list of images\n",
    "                    images.append(np_img)\n",
    "                    # Adds what fruit the image is to target list\n",
    "                    targets.append(root[len(dir)+1:len(root)])\n",
    "    X = np.array(images).astype(np.float32)\n",
    "    return X.reshape((X.shape[0],100,100,1))/255.0 - 0.5, targets\n",
    "\n",
    "# Get training and test data\n",
    "X_train, y_train = get_data('fruit_dataset/train/train')\n",
    "X_test, y_test = get_data('fruit_dataset/test/test')\n",
    "\n",
    "print(len(y_train), 'training pictures loaded.')\n",
    "print(len(y_test), 'test images loaded.')\n",
    "\n",
    "labels = np.unique(y_train)\n",
    "NUM_CLASSES = len(labels)\n",
    "print('Num Classes:', NUM_CLASSES)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75de584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train).astype(np.int32)\n",
    "y_test = le.transform(y_test).astype(np.int32)\n",
    "\n",
    "# make one- hot encoded versions of the data\n",
    "y_train_ohe = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test_ohe = keras.utils.to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2abd92",
   "metadata": {},
   "source": [
    "#### 2.1b Data expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59b8e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=5, # used, Int. Degree range for random rotations.\n",
    "    width_shift_range=0.1, # used, Float (fraction of total width). Range for random horizontal shifts.\n",
    "    height_shift_range=0.1, # used,  Float (fraction of total height). Range for random vertical shifts.\n",
    "    shear_range=0., # Float. Shear Intensity (Shear angle in counter-clockwise direction as radians)\n",
    "    zoom_range=0.,\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    rescale=None)\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1062ec68",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2 Create a Convolutional Neural Network to use on your Data using Keras\n",
    "Create a convolutional neural network to use on your data using Keras. Investigate at least two different convolutional network architectures (and investigate changing some parameters of each architecture such as the number of filters--at minimum have two variations of each network for a total of four models trained). Use the method of train/test splitting and evaluation metric that you argued for at the beginning of the lab. Visualize the performance of the training and validation sets per iteration (use the \"history\" parameter of Keras). Be sure that models converge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fc91b0",
   "metadata": {},
   "source": [
    "#### 2.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f95d060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 19:03:41.381518: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528/528 [==============================] - 73s 138ms/step - loss: 0.0076 - accuracy: 0.0136 - val_loss: 0.0076 - val_accuracy: 0.0134\n",
      "Epoch 2/5\n",
      "528/528 [==============================] - 73s 138ms/step - loss: 0.0076 - accuracy: 0.0143 - val_loss: 0.0076 - val_accuracy: 0.0145\n",
      "Epoch 3/5\n",
      "528/528 [==============================] - 74s 139ms/step - loss: 0.0076 - accuracy: 0.0145 - val_loss: 0.0076 - val_accuracy: 0.0145\n",
      "Epoch 4/5\n",
      "528/528 [==============================] - 74s 141ms/step - loss: 0.0076 - accuracy: 0.0145 - val_loss: 0.0076 - val_accuracy: 0.0145\n",
      "Epoch 5/5\n",
      "528/528 [==============================] - 75s 141ms/step - loss: 0.0076 - accuracy: 0.0146 - val_loss: 0.0076 - val_accuracy: 0.0145\n",
      "CPU times: user 29min 52s, sys: 3min 44s, total: 33min 36s\n",
      "Wall time: 6min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# changes: \n",
    "#    1. Baseline: 2 conv layers and two output layers\n",
    "cnn1 = Sequential()\n",
    "\n",
    "num_filt_layers = [24, 24]\n",
    "for num_filters in num_filt_layers:\n",
    "    cnn1.add( Conv2D(filters=num_filters, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding='same',data_format=\"channels_last\") )\n",
    "    cnn1.add( Activation('relu'))\n",
    "    cnn1.add( MaxPooling2D(pool_size=(2, 2), \n",
    "                           data_format=\"channels_last\") )\n",
    "    \n",
    "\n",
    "# add one layer on flattened output\n",
    "cnn1.add( Flatten() )\n",
    "cnn1.add( Dense(100, activation='relu') )\n",
    "cnn1.add( Dense(100, activation='relu') )\n",
    "cnn1.add( Dense(NUM_CLASSES, activation='softmax') )\n",
    "\n",
    "# # Let's train the model \n",
    "cnn1.compile(loss='mean_squared_error',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# # we need to exapnd the dimensions here to give the \n",
    "# #   \"channels\" dimension expected by Keras\n",
    "cnn1History = cnn1.fit(datagen.flow(X_train, y_train_ohe, batch_size=128), \n",
    "                   steps_per_epoch=int(len(X_train)/128), # how many generators to go through per epoch\n",
    "                   epochs=5, verbose=1,\n",
    "                   validation_data=(X_test,y_test_ohe)\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b078d9",
   "metadata": {},
   "source": [
    "#### 2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310f278d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "528/528 [==============================] - 215s 407ms/step - loss: 4.8941 - accuracy: 0.0141 - val_loss: 4.8593 - val_accuracy: 0.0145\n",
      "Epoch 2/5\n",
      "528/528 [==============================] - 266s 504ms/step - loss: 4.8590 - accuracy: 0.0145 - val_loss: 4.8569 - val_accuracy: 0.0145\n",
      "Epoch 3/5\n",
      "215/528 [===========>..................] - ETA: 6:48 - loss: 4.8572 - accuracy: 0.0148"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Copy TensorFlow Architecture from \n",
    "#   Deep MNIST for experts\n",
    "#   https://www.tensorflow.org/versions/r0.11/tutorials/mnist/pros/index.html\n",
    "\n",
    "# Manipulated to mirror parts of this network:\n",
    "#   http://ankivil.com/mnist-database-and-simple-classification-networks/\n",
    "\n",
    "cnn2 = Sequential()\n",
    "\n",
    "num_filt_layers = [32, 64]\n",
    "for num_filters in num_filt_layers:\n",
    "    cnn2.add( Conv2D(filters=num_filters, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding='same', \n",
    "                    activation='relu',\n",
    "                    data_format=\"channels_last\") ) # more compact syntax\n",
    "\n",
    "    # max pooling\n",
    "    cnn2.add( MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\") )\n",
    "    \n",
    "\n",
    "# add one layer on flattened output\n",
    "cnn2.add( Dropout(0.25) ) # add some dropout for regularization after conv layers\n",
    "cnn2.add( Flatten() )\n",
    "cnn2.add( Dense(1024, activation='relu') )\n",
    "cnn2.add( Dropout(0.5) ) # add some dropout for regularization, again!\n",
    "cnn2.add( Dense(NUM_CLASSES, activation='softmax') )\n",
    "\n",
    "# Let's train the model \n",
    "cnn2.compile(loss='categorical_crossentropy', # 'categorical_crossentropy' 'mean_squared_error'\n",
    "              optimizer='rmsprop', # 'adadelta' 'rmsprop'\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# we need to exapnd the dimensions here to give the \n",
    "#   \"channels\" dimension expected by Keras\n",
    "cnn2History = cnn2.fit(datagen.flow(X_train, y_train_ohe, batch_size=128), \n",
    "                   steps_per_epoch=int(len(X_train)/128), # how many generators to go through per epoch\n",
    "                   epochs=5, verbose=1,\n",
    "                   validation_data=(X_test,y_test_ohe)\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d851808c",
   "metadata": {},
   "source": [
    "#### 2.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3abfee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# changes: \n",
    "#    3. Baseline (1) + Changed second layer of filters from 24 to 48\n",
    "cnn3 = Sequential()\n",
    "\n",
    "num_filt_layers = [24, 48]\n",
    "for num_filters in num_filt_layers:\n",
    "    cnn3.add( Conv2D(filters=num_filters, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding='same',data_format=\"channels_last\") )\n",
    "    cnn3.add( Activation('relu'))\n",
    "    cnn3.add( MaxPooling2D(pool_size=(2, 2), \n",
    "                           data_format=\"channels_last\") )\n",
    "    \n",
    "\n",
    "# add one layer on flattened output\n",
    "cnn3.add( Flatten() )\n",
    "cnn3.add( Dense(100, activation='relu') )\n",
    "cnn3.add( Dense(100, activation='relu') )\n",
    "cnn3.add( Dense(NUM_CLASSES, activation='softmax') )\n",
    "\n",
    "# # Let's train the model \n",
    "cnn3.compile(loss='mean_squared_error',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# # we need to exapnd the dimensions here to give the \n",
    "# #   \"channels\" dimension expected by Keras\n",
    "cnn3History = cnn3.fit(datagen.flow(X_train, y_train_ohe, batch_size=128), \n",
    "                   steps_per_epoch=int(len(X_train)/128), # how many generators to go through per epoch\n",
    "                   epochs=5, verbose=1,\n",
    "                   validation_data=(X_test,y_test_ohe)\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7a74da",
   "metadata": {},
   "source": [
    "#### 2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ec93c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# changes: \n",
    "#    4. CNN2 + Changed first layer of filters from 32 to 16\n",
    "\n",
    "cnn4 = Sequential()\n",
    "\n",
    "num_filt_layers = [16, 64]\n",
    "for num_filters in num_filt_layers:\n",
    "    cnn4.add( Conv2D(filters=num_filters, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding='same', \n",
    "                    activation='relu',\n",
    "                    data_format=\"channels_last\") ) # more compact syntax\n",
    "\n",
    "    # max pooling\n",
    "    cnn4.add( MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\") )\n",
    "    \n",
    "\n",
    "# add one layer on flattened output\n",
    "cnn4.add( Dropout(0.25) ) # add some dropout for regularization after conv layers\n",
    "cnn4.add( Flatten() )\n",
    "cnn4.add( Dense(1024, activation='relu') )\n",
    "cnn4.add( Dropout(0.5) ) # add some dropout for regularization, again!\n",
    "cnn4.add( Dense(NUM_CLASSES, activation='softmax') )\n",
    "\n",
    "# Let's train the model \n",
    "cnn4.compile(loss='categorical_crossentropy', # 'categorical_crossentropy' 'mean_squared_error'\n",
    "              optimizer='rmsprop', # 'adadelta' 'rmsprop'\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# we need to exapnd the dimensions here to give the \n",
    "#   \"channels\" dimension expected by Keras\n",
    "cnn4History = cnn4.fit(datagen.flow(X_train, y_train_ohe, batch_size=128), \n",
    "                   steps_per_epoch=int(len(X_train)/128), # how many generators to go through per epoch\n",
    "                   epochs=5, verbose=1,\n",
    "                   validation_data=(X_test,y_test_ohe)\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f66cfc",
   "metadata": {},
   "source": [
    "#### 2.3 Visualize the Results of the CNNs\n",
    " Visualize the final results of the CNNs and interpret/compare the performances. Use proper statistics as appropriate, especially for comparing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f463ffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as mt\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# combine all the history from training together\n",
    "def areaUnderCurveGraphs(history, title):\n",
    "    combined = dict()\n",
    "#     for key in ['accuracy','val_accuracy','loss','val_loss']:\n",
    "    for key in ['accuracy','loss']:\n",
    "        combined[key] = np.hstack(history.history[key])\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(combined['accuracy'])\n",
    "#     plt.plot(combined['val_acc'])\n",
    "    plt.title(title + ' model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.subplot(122)\n",
    "    plt.plot(combined['loss'])\n",
    "#     plt.plot(combined['val_loss'])\n",
    "    plt.title(title + ' model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa447fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CNN1:',cnn1.evaluate(X_test,y_test_ohe,verbose=0))\n",
    "areaUnderCurveGraphs(cnn1Histories, 'CNN1')\n",
    "\n",
    "print('CNN2:',cnn2.evaluate(X_test,y_test_ohe,verbose=0))\n",
    "areaUnderCurveGraphs(cnn2Histories, 'CNN2')\n",
    "\n",
    "print('CNN3:',cnn3.evaluate(X_test,y_test_ohe,verbose=0))\n",
    "areaUnderCurveGraphs(cnn3Histories, 'CNN3')\n",
    "\n",
    "print('CNN4:',cnn4.evaluate(X_test,y_test_ohe,verbose=0))\n",
    "areaUnderCurveGraphs(cnn4Histories, 'CNN4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74dac0c",
   "metadata": {},
   "source": [
    "#### 2.4 Compare the CNN to a MLP\n",
    "Compare the performance of your convolutional network to a standard multi-layer perceptron (MLP) using the receiver operating characteristic and area under the curve. Use proper statistical comparison techniques.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad48771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# make a keras MLP\n",
    "mlp = Sequential()\n",
    "mlp.add( Flatten() )\n",
    "mlp.add( Dense(input_dim=X_train.shape[1], units=100, activation='relu') )\n",
    "mlp.add( Dense(units=50, activation='relu') )\n",
    "mlp.add( Dense(units=50, activation='relu') )\n",
    "mlp.add( Dense(NUM_CLASSES) )\n",
    "mlp.add( Activation('softmax') )\n",
    "\n",
    "mlp.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "mlpHistory = mlp.fit(X_train, y_train_ohe, \n",
    "        batch_size=32, epochs=15, \n",
    "        shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b37f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "areaUnderCurveGraphs(cnn1Histories, 'CNN1')\n",
    "areaUnderCurveGraphs(mlpHistory, 'MLP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d6403f",
   "metadata": {},
   "source": [
    "### 3. Transfer Learning to Pre-Train the Weights of your Initial Layers of your CNN\n",
    "Use transfer learning to pre-train the weights of your initial layers of your CNN. Compare the performance when using transfer learning to training without transfer learning (i.e., compare to your best model from above) in terms of classification performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fdb7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
