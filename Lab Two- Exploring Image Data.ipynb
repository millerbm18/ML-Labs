{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00365c10",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Lab Assignment Two: Exploring Image Data \n",
    "\n",
    "#### Everett Cienkus, Blake Miller, Colin Weil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c8fc71",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. Business Understanding\n",
    "\n",
    "The data set is a collection of images of 131 different types of fruits, vegetables, or nuts (AKA food items). These are 100x100 px images with a single food item and a white background. There are a total of 67692 images to train and 22688 images to test the accuracy of the data set. This image data was collected by Mihai Oltean for the purpose of documenting the 360 degree views of fruits. These fruits were filmed using a stationary camera, a slow rotating motor, and a white background. The different food items were placed on a rod attached to the motor and slowly spun while the camera captured the different angles of the food item. The white background was not consistent throughout the photos and negatively impacted the ability to declare the food item from the background. To combat this the collectors created an algorithm that removed the background of the images and replaced it with the color white. \n",
    "\n",
    "The prediction task for this dataset is to use the images of food items in the train set to identify the food items in the images in the test data. Third parties that would be interested in these results would be someone creating a mobile app that allows the user to identify food items. Typically, a person would know the different food items within their own home and grocery stores label their items, leaving no need for the app in these situations. However, when people travel to foreign countries, they may see food items on a tree or bush or vine and want to identify this item. Farmers could also program this intelligence into their machines, allowing automatic picking machines to identify where these food items are or how many are left that have not been harvested. (Maybe just stick to the farmer one I am not 100% sure and then I can write the % accuracy based on specifics)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f074a40e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "### 2. Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "806b4b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from numpy import asarray\n",
    "\n",
    "    \n",
    "changeListToSingleValue_vec = lambda i: int(''.join(map(str, i)))\n",
    "\n",
    "images = []\n",
    "\n",
    "directory = 'fruit_dataset/test'\n",
    "\n",
    "for root, dirs, files in os.walk(directory):\n",
    "     for file in files:\n",
    "        with open(os.path.join(root, file), \"r\") as auto:\n",
    "            if(file.lower().endswith(('.jpg'))):\n",
    "                # Read in image as numpy arrays\n",
    "                img= Image.open(os.path.join(root, file))\n",
    "                # Recolor to black and white and flatten to 1D array\n",
    "                np_img = np.array(img.convert('L')).flatten()\n",
    "                # Add to list of images\n",
    "                images.append(np_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706588da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Several Images\n",
    "display(Image.fromarray(images[0].reshape(100,100), 'L'))\n",
    "display(Image.fromarray(images[20].reshape(100,100), 'L'))\n",
    "display(Image.fromarray(images[100].reshape(100,100), 'L'))\n",
    "display(Image.fromarray(images[500].reshape(100,100), 'L'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5ae790",
   "metadata": {},
   "source": [
    "### 3. Data Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef36c803",
   "metadata": {},
   "source": [
    "#### 3.1 Linear dimensionality reduction PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7978d77b",
   "metadata": {},
   "source": [
    "#### 3.2 randomized principle components analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed146df6",
   "metadata": {},
   "source": [
    "#### 3.3 Compare PCA and Randomized PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff748606",
   "metadata": {},
   "source": [
    "#### 3.4 feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890479f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explanation of feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5fbed5",
   "metadata": {},
   "source": [
    "### 4. DAISY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
